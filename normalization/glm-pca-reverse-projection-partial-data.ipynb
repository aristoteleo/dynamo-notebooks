{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of glm-pca on zebrafish data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial uses data from [Saunders, et al (2019)](https://elifesciences.org/articles/45181). Special thanks also go to [Lauren](https://twitter.com/LSaund11) for the tutorial improvement. \n",
    "\n",
    "In this [study](https://elifesciences.org/articles/45181), the authors profiled thousands of neural crest-derived cells from trunks of post-embryonic zebrafish. These cell classes include pigment cells, multipotent pigment cell progenitors, peripheral neurons, Schwann cells, chromaffin cells and others. These cells were collected during an active period of post-embryonic development, which has many similarities to fetal and neonatal development in mammals, when many of these cell types are migrating and differentiating as the animal transitions into its adult form. This study also explores the role of thyroid hormone (TH), a common endocrine factor, on the development of these different cell types. \n",
    "\n",
    "Such developmental and other dynamical processes are especially suitable for dynamo analysis as dynamo is designed to accurately estimate direction and magnitude of expression dynamics (`RNA velocity`), predict the entire lineage trajectory of any intial cell state (`vector field`), characterize the structure (`vector field topology`) of full gene expression space, as well as fate commitment potential (`single cell potential`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the package and silence some warning information (mostly `is_categorical_dtype` warning from anndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import dynamo as dyn \n",
    "from dynamo.configuration import DKM\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is like R's sessionInfo() which helps you to debug version related bugs if any. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>package</th>\n",
       "      <th>dynamo-release</th>\n",
       "      <th>pre-commit</th>\n",
       "      <th>colorcet</th>\n",
       "      <th>cvxopt</th>\n",
       "      <th>hdbscan</th>\n",
       "      <th>loompy</th>\n",
       "      <th>matplotlib</th>\n",
       "      <th>networkx</th>\n",
       "      <th>numba</th>\n",
       "      <th>numdifftools</th>\n",
       "      <th>numpy</th>\n",
       "      <th>pandas</th>\n",
       "      <th>pynndescent</th>\n",
       "      <th>python-igraph</th>\n",
       "      <th>scikit-learn</th>\n",
       "      <th>scipy</th>\n",
       "      <th>seaborn</th>\n",
       "      <th>setuptools</th>\n",
       "      <th>statsmodels</th>\n",
       "      <th>tqdm</th>\n",
       "      <th>trimap</th>\n",
       "      <th>umap-learn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>version</th>\n",
       "      <td>1.0.0</td>\n",
       "      <td>2.15.0</td>\n",
       "      <td>2.0.6</td>\n",
       "      <td>1.2.7</td>\n",
       "      <td>0.8.27</td>\n",
       "      <td>3.0.6</td>\n",
       "      <td>3.4.3</td>\n",
       "      <td>2.6.3</td>\n",
       "      <td>0.54.0</td>\n",
       "      <td>0.9.40</td>\n",
       "      <td>1.20.3</td>\n",
       "      <td>1.3.3</td>\n",
       "      <td>0.5.4</td>\n",
       "      <td>0.9.6</td>\n",
       "      <td>0.24.2</td>\n",
       "      <td>1.7.1</td>\n",
       "      <td>0.11.2</td>\n",
       "      <td>58.0.4</td>\n",
       "      <td>0.12.2</td>\n",
       "      <td>4.62.3</td>\n",
       "      <td>1.0.15</td>\n",
       "      <td>0.5.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "package dynamo-release pre-commit colorcet cvxopt hdbscan loompy matplotlib  \\\n",
       "version          1.0.0     2.15.0    2.0.6  1.2.7  0.8.27  3.0.6      3.4.3   \n",
       "\n",
       "package networkx   numba numdifftools   numpy pandas pynndescent  \\\n",
       "version    2.6.3  0.54.0       0.9.40  1.20.3  1.3.3       0.5.4   \n",
       "\n",
       "package python-igraph scikit-learn  scipy seaborn setuptools statsmodels  \\\n",
       "version         0.9.6       0.24.2  1.7.1  0.11.2     58.0.4      0.12.2   \n",
       "\n",
       "package    tqdm  trimap umap-learn  \n",
       "version  4.62.3  1.0.15      0.5.1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dyn.get_all_dependencies_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data \n",
    "\n",
    "Dynamo comes with a few builtin sample datasets so you can familiarize with dynamo before analyzing your own dataset.\n",
    "You can read your own data via `read`, `read_loom`, `read_h5ad`, `read_h5` (powered by the [anndata](https://anndata.readthedocs.io/en/latest/anndata.AnnData.html) package) or load_NASC_seq, etc. Here I just load the zebrafish sample data that comes with dynamo. This dataset has 4181 cells and 16940 genes. Its `.obs` attribute also included `condition`, `batch` information from the original study (you should also store those information to your `.obs` attribute which is essentially a Pandas Dataframe, see more at [anndata](https://anndata.readthedocs.io/en/latest/)). `Cluster`, `Cell_type`, umap coordinates that was originally analyzed with [Monocle 3](https://cole-trapnell-lab.github.io/monocle3/) are also provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|-----> Downloading data to ./data/zebrafish.h5ad\n"
     ]
    }
   ],
   "source": [
    "adata = dyn.sample_data.zebrafish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "from scipy import sparse\n",
    "import anndata\n",
    "def remove_rare_genes(counts,genes,minimum_detected_cells_per_gene):\n",
    "    \n",
    "    if type(counts) in [sparse.csr.csr_matrix, sparse.csc.csc_matrix]:\n",
    "        \n",
    "        #remove zero genes\n",
    "        nonzero_genes_idx = np.array(counts.sum(axis=0)).flatten() > 0\n",
    "\n",
    "        counts = counts[:,nonzero_genes_idx]\n",
    "        genes = genes[nonzero_genes_idx]\n",
    "\n",
    "        #count nonzero entries per gene\n",
    "        nonzero_coords = counts.nonzero()\n",
    "        n_nonzero = counts.count_nonzero()\n",
    "        is_nonzero = sparse.csc_matrix((np.ones(n_nonzero),nonzero_coords))\n",
    "        detected_cells_per_gene = np.array(is_nonzero.sum(axis=0)).flatten()\n",
    "\n",
    "        keep_genes = detected_cells_per_gene >= minimum_detected_cells_per_gene    \n",
    "        counts_kept = counts[:,keep_genes]\n",
    "        genes_kept = genes[keep_genes]\n",
    "\n",
    "        print('Of',len(detected_cells_per_gene),'total genes, returning',sum(keep_genes),'genes that are detected in %u or more cells.' % (minimum_detected_cells_per_gene))\n",
    "        print('Output shape:', counts_kept.shape)\n",
    "\n",
    "        return counts_kept,np.array(genes_kept)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        #remove zero genes\n",
    "        nonzero_genes_idx = np.sum(counts,axis=0) > 0\n",
    "        counts = counts[:,nonzero_genes_idx]\n",
    "        genes = genes[nonzero_genes_idx]        \n",
    "        \n",
    "        #remove genes that are detected in less then n cells\n",
    "        nonzero = counts > 0\n",
    "        cells_per_gene = np.sum(nonzero,axis=0)\n",
    "        include_genes = cells_per_gene >= minimum_detected_cells_per_gene\n",
    "        counts_kept = counts[:,include_genes]\n",
    "        genes_kept = genes[include_genes]\n",
    "        print('Of',len(cells_per_gene),'total genes, returning',sum(include_genes),'genes that are detected in %u or more cells.' % (minimum_detected_cells_per_gene))\n",
    "        print('Output shape:', counts_kept.shape)\n",
    "        return counts_kept,genes_kept\n",
    "\n",
    "def preprocess_adata_pearson_paper(adata):\n",
    "    counts, genes, cells = adata.X, np.array(adata.var_names), adata.obs_names\n",
    "\n",
    "    counts = counts.toarray()\n",
    "    \n",
    "    #remove low depth cells\n",
    "    depths = np.array(np.sum(counts,axis=1)).flatten()\n",
    "    minimum_depth = 500\n",
    "    cells = cells[depths>minimum_depth]\n",
    "    counts = counts[depths>minimum_depth,:]\n",
    "    print('Of',len(depths),'cells, returning',sum(depths>minimum_depth),'cells that have a depth larger than', minimum_depth)\n",
    "    print('New shape:', counts.shape)    \n",
    "    \n",
    "    counts, genes = remove_rare_genes(counts,genes,minimum_detected_cells_per_gene=5)\n",
    "    counts = sparse.csr_matrix(counts)\n",
    "    print(np.unique(cells))\n",
    "    print(genes)\n",
    "    res = adata[:, np.unique(genes)]\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata[['AAACCTGAGTCTTGCA-1-1', 'AAACCTGCAAACTGTC-1-0'],]\n",
    "# adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "def compute_marginals(counts):\n",
    "    '''compute depths per cell (ns) and relative expression fractions per gene (ps)'''\n",
    "    ns = np.sum(counts,axis=1)\n",
    "    ps = np.sum(counts,axis=0)\n",
    "    ps = ps / np.sum(ps)    \n",
    "    return np.squeeze(np.array(ns)), np.squeeze(np.array(ps))\n",
    "\n",
    "def monitor_progress(gene_id,n_genes,print_time_every=1000,print_dot_every=25):\n",
    "    if np.mod(gene_id,print_time_every)==0:\n",
    "        print('')\n",
    "        print('##',datetime.now().time(),'##',gene_id,'of',n_genes,'genes fit',end='')\n",
    "    if np.mod(gene_id,print_dot_every)==0:\n",
    "        print('.',end='')\n",
    "\n",
    "def fit_offsetmodel_w_statsmodel(counts,depths,name):\n",
    "    '''use statsmodel to fit offsetmodel (Eq. 3) and obtain beta0 (intercept) estimates, saving results to file'''\n",
    "    n_cells = counts.shape[0]\n",
    "    n_genes = counts.shape[1]    \n",
    "    \n",
    "    ##np.ones: will fit intercept beta0\n",
    "    X = np.ones((n_cells,1))\n",
    "    ##log(depths): will be used as offsets\n",
    "    logdepths = np.log(depths)\n",
    "\n",
    "    beta0 = np.zeros(n_genes) * np.nan\n",
    "    for gene_id in range(n_genes):        \n",
    "        offsetmodel = sm.Poisson(counts[:,gene_id], X, offset = logdepths)\n",
    "        result = offsetmodel.fit(disp=0)\n",
    "        beta0[gene_id] = result.params\n",
    "        \n",
    "        monitor_progress(gene_id,n_genes)\n",
    "    res = dict(beta0=beta0)\n",
    "    # np.save('fit_results/fit_offsetmodel_w_statsmodel_%s' % (name),res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of 4181 cells, returning 4157 cells that have a depth larger than 500\n",
      "New shape: (4157, 16940)\n",
      "Of 16589 total genes, returning 14555 genes that are detected in 5 or more cells.\n",
      "Output shape: (4157, 14555)\n",
      "['AAACCTGAGTCTTGCA-1-1' 'AAACCTGCAAACTGTC-1-0' 'AAACCTGCAGTCGATT-1-0' ...\n",
      " 'TTTGTCACATTCGACA-1-1' 'TTTGTCAGTAATCACC-1-1' 'TTTGTCAGTCTCTTTA-1-1']\n",
      "['tmsb4x' 'rpl8' 'ppiaa' ... 'CR450726.1' 'rasef' 'ghrh']\n"
     ]
    }
   ],
   "source": [
    "adata = preprocess_adata_pearson_paper(adata)\n",
    "dyn.reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np array conversion complete\n",
      "running customized glm-pca ver...\n"
     ]
    }
   ],
   "source": [
    "import glmpca\n",
    "count_mat_T_array = adata.X.T.toarray()\n",
    "print(\"np array conversion complete\")\n",
    "result = glmpca.glmpca.glmpca(count_mat_T_array, 50)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c0f224693fc3f3b337b469fdaf7389d3b291b17a90dca45f35bda4453932d9dd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('dynamo-dev': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
